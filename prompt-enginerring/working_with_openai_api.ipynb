{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Set ups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# send request\n",
    "# Create the OpenAI client\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Create a request to the Chat Completions endpoint\n",
    "response = client.chat.completions.create(\n",
    "  # Specify the correct model\n",
    "  model=\"gpt-4o-mini\",      ## -- this model returns the most possible result\n",
    "  # Specify the message keys\n",
    "  messages=[{\"role\": \"user\", \"content\": \"Who developed ChatGPT?\"}]\n",
    ")\n",
    "\n",
    "\n",
    "# Usually wrapped up as \"get_response\" function\n",
    "def get_response(message):\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=[{\"role\": \"user\", \"content\": message}]\n",
    "    )\n",
    "    return response.choices[0].message['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extracting from response\n",
    "\n",
    "# extract the model used\n",
    "print(response.model)\n",
    "\n",
    "# extract the text from response\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temperature parameter: control determinism\n",
    "# 0 = deterministic ~ 2 = random\n",
    "\n",
    "# max_tokens: change length of response\n",
    "# will increase cost!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Zero-shot: no example provided for the model to learn\n",
    "One-shot, few-shot  - as indicated by the names\n",
    "\n",
    "You can share examples and add classifications after \"//\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-turn tasks (chat competions)\n",
    "- role \"system\" controls how \"assistant\" helps the \"user\". Controls assistant's behavior\n",
    "\n",
    "- Can provide examples to guide the response. \n",
    "    = method 1: In-text learning - by including {\"role\":\"assistant\", \"content\":\"example content\"} in messages\n",
    "    = method 2: Store response - create chat history, do back-and-forth convo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of \"Store response\":\n",
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "messages = [{\"role\": \"system\", \"content\": \"You are a helpful math tutor.\"}]\n",
    "user_msgs = [\"Explain what pi is.\", \"Summarize this in two bullet points.\"]\n",
    "\n",
    "for q in user_msgs:\n",
    "    print(\"User: \", q)\n",
    "    \n",
    "    # Create a dictionary for the user message from q and append to messages\n",
    "    user_dict = {\"role\": 'user', \"content\": q}\n",
    "    messages.append(user_dict)\n",
    "    \n",
    "    # Create the API request\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages = messages,\n",
    "        max_tokens=100\n",
    "    )\n",
    "    \n",
    "    # Convert the assistant's message to a dict and append to messages\n",
    "    assistant_dict = {\"role\": 'assistant', \"content\": response.choices[0].message.content}\n",
    "    messages.append(assistant_dict)\n",
    "    print(\"Assistant: \", response.choices[0].message.content, \"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = 'text-moderation-lastest\" \n",
    "Allows you to do text moderation tasks (censorship)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Create a request to the Moderation endpoint\n",
    "response = client.moderations.create(\n",
    "    model = 'text-moderation-latest',\n",
    "    input ='My favorite book is To Kill a Mockingbird'\n",
    ")\n",
    "\n",
    "# Print the category scores\n",
    "print(response.model_dump())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whisper: speech-to-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcription request\n",
    "response = client.audio.transcriptions.create(model=\"whisper-1\", file = input_audio_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transcribing & translating at the same time\n",
    "# only support English tho (at this point)\n",
    "prompt = \"Use less filler word. This audio is about X industry.\"\n",
    "response = client.audio.translations.create(model=\"whisper-1\", file = input_audio_file, prompt=prompt)\n",
    "\n",
    "# can provide examples tell the model about ur preferences\n",
    "# e.g. less filler word"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combining models\n",
    "\n",
    "1 - Chaining. Feeding output from one model into another\n",
    "\n",
    "    = can be same model\n",
    "    = can be a different one\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Open the audio.wav file\n",
    "audio_file = open(\"audio.wav\", \"rb\")\n",
    "\n",
    "# Create a transcription request using audio_file\n",
    "audio_response = client.audio.transcriptions.create(\n",
    "    model='whisper-1',\n",
    "    file=audio_file\n",
    ")\n",
    "\n",
    "transcript = audio_response.text\n",
    "message = \"Tell me what language was used in this text: \"+ transcript\n",
    "\n",
    "# Create a request to the API to identify the language spoken\n",
    "chat_response = client.chat.completions.create(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    messages = [\n",
    "        {\"role\":'user', 'content':message}]\n",
    ")\n",
    "print(chat_response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-shot & Few-shot questions\n",
    "provide examples for the model to learn. The more complex the task, the more examples you ought to provide"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-step prompts\n",
    "- for sequential and cognitive tasks\n",
    "Give steps gpt should follow. Nothing special..\n",
    "(proactive)\n",
    "\n",
    "Chain-of-thought prompts\n",
    "Ask the model to generate intermediate thoughts\n",
    "(reactive)\n",
    "Risk: one flawed step leads to unsuccessful outcome\n",
    "\n",
    "Self-consistency prompting\n",
    "Generate multiple Chain-of-thought prompts by prompting the model several times\n",
    "Determined by majority voting\n",
    "\"Provide 3 diffrent method in reasoning while answering this question. Final answer is obtained by majority vote\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use OpenAI for chatbot developments\n",
    "- system prompt: define the purpose + specify the bot's role (it then knows how to answer 'who are you') + able to provide domain-specified knowledge\n",
    "-- advanced: specify tone, audience, length, and structure\n",
    "-- behavior guidance: conditional prompts. \"If question in this field, answer at your best. If not, say 'idk'\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI(api_key=\"<OPENAI_API_TOKEN>\")\n",
    "\n",
    "# Define the purpose of the chatbot\n",
    "chatbot_purpose = \"You're a customer support chatbot for an e-commerce company specializing in electronics. You'll assist users with inquiries, order tracking, and troubleshooting common issues. \"\n",
    "\n",
    "# Define audience guidelines\n",
    "audience_guidelines = \"The audience are tech-savvy individuals interested in purchasing electronic gadgets.\"\n",
    "\n",
    "# Define tone guidelines\n",
    "tone_guidelines = \"Use a professional and user-friendly tone\"\n",
    "\n",
    "system_prompt = chatbot_purpose + audience_guidelines + tone_guidelines\n",
    "response = get_response(system_prompt, \"My new headphones aren't connecting to my device\")\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
