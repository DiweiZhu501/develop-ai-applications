{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing\n",
    "\n",
    "Cropping\n",
    "- remove wanted protion\n",
    "\n",
    "Resizing\n",
    "- change dimension of image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforming images\n",
    "from transformers import image_transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "original_image = Image.open('image.jpg') #just imagine there's one\n",
    "# Create the numpy array\n",
    "image_array = np.array(original_image)\n",
    "\n",
    "# Crop the center of the image\n",
    "cropped_image = image_transforms.center_crop(image=image_array, size=(200, 200))\n",
    "\n",
    "imgplot = plt.imshow(cropped_image)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# image classification\n",
    "# Create the pipeline\n",
    "image_classifier = pipeline(task=\"image-classification\", \n",
    "            model=\"abhishek/autotrain_fashion_mnist_vit_base\")\n",
    "\n",
    "# Predict the class of the image\n",
    "results = image_classifier(cropped_image)\n",
    "\n",
    "# Print the results\n",
    "print(results[0][\"label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### document/visual question & answering\n",
    "Answering question based on a provided document, content can be text or image\n",
    "visual: answering question based on provided image or video\n",
    "\n",
    "Different from classifying & labeling, this involves answering questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the pipeline\n",
    "dqa = pipeline(task=\"document-question-answering\", model=\"naver-clova-ix/donut-base-finetuned-docvqa\")\n",
    "vqa = pipeline(task=\"image-question-answering\", model=\"vinai/bert-base-cased-vqa\")  # what is this species in the picture?\n",
    "\n",
    "# Set the image and question\n",
    "image = \"document.png\"\n",
    "question = \"Which meeting is this document about?\"\n",
    "\n",
    "# Get the answer\n",
    "results = dqa(image=image, question=question)\n",
    "\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Audio classification/Automatic speech recognition\n",
    "Based on length and amplitude, sound wave can be converted to discrete values (digital representation) and then analyzed.\n",
    "Speech models trained at 16hz\n",
    "\n",
    "Resampling\n",
    "- allows same sampling rate across all files to ensure consistency\n",
    "\n",
    "Filtering\n",
    "- ensuring enough sample size\n",
    "- reduce computation by limiting file size\n",
    "- Librosa library is for this task\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##  change sampling rate\n",
    "# Save the old sampling rate\n",
    "old_sampling_rate = audio_file[1][\"audio\"][\"sampling_rate\"]\n",
    "# Resample the audio files\n",
    "# change the sampling rate to 16000 Hz for column \"audio\"\n",
    "audio_file = audio_file.cast_column(\"audio\", Audio(sampling_rate=16_000))\n",
    "# Compare the old and new sampling rates\n",
    "print(\"Old sampling rate:\", old_sampling_rate)\n",
    "print(\"New sampling rate:\", audio_file[1][\"audio\"][\"sampling_rate\"])\n",
    "\n",
    "\n",
    "## Filter audios based on duration\n",
    "# Create a list of durations\n",
    "old_durations_list = []\n",
    "# Loop over the dataset\n",
    "for row in dataset[\"path\"]:\n",
    "    old_durations_list.append(librosa.get_duration(path=row))\n",
    "# Create a new column\n",
    "dataset = dataset.add_column(\"duration\", old_durations_list)\n",
    "# Filter the dataset\n",
    "filtered_dataset = dataset.filter(lambda d: d < 6.0, input_columns=[\"duration\"], keep_in_memory=True)\n",
    "\n",
    "\n",
    "## audio classification\n",
    "# Create the pipeline\n",
    "classifier = pipeline(task=\"audio-classification\", model=\"facebook/mms-lid-126\")\n",
    "# Extract the sample\n",
    "audio = dataset[1][\"audio\"][\"array\"]  # extract np array that stores discreted audio\n",
    "sentence = dataset[1][\"sentence\"]\n",
    "# Predict the language\n",
    "prediction = classifier(audio)\n",
    "print(f\"Predicted language is '{prediction[0]['label'].upper()}' for the sentence '{sentence}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Automatic Speech Recognition (ASR)\n",
    "Use Word Error Rate (WER) to evaluate the ASR systems. Ranges to 0 - 1, the smaller the number, the more accurate the prediction.\n",
    "Can be calculated using Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## asr with Open AI's whisper model\n",
    "open_asr = pipeline(task=\"automatic-speech-recognition\", model=\"openai/whisper-tiny\")\n",
    "open_pred = open_asr(example[\"audio\"][\"array\"])[\"text\"].lower()\n",
    "\n",
    "\n",
    "## calculate WER\n",
    "from evaluate import load\n",
    "# Create the word error rate metric\n",
    "wer = load(\"wer\")\n",
    "# Save the true sentence of the example\n",
    "true_sentence = example[\"sentence\"].lower()\n",
    "open_wer = wer.compute(predictions=[open_pred], references=[true_sentence])\n",
    "\n",
    "\n",
    "\n",
    "## Run asr for a larger number of audios\n",
    "# Create the data function\n",
    "def data(n=3):\n",
    "    for i in range(n):\n",
    "        yield english[i][\"audio\"][\"array\"], english[i][\"sentence\"].lower() \n",
    "\n",
    "# The data function uses lazy evaluation with the yield keyword. \n",
    "# Instead of loading all audio files into memory at once (which could take a lot of time and resources), it yields one audio file and its corresponding text at a time. \n",
    "# Ensures lower memory usage and less initialization time.\n",
    "\n",
    "# Predict the text for the audio file with both models\n",
    "output = []\n",
    "for audio, sentence in data():\n",
    "    meta_pred = meta_asr(audio)[\"text\"].lower()\n",
    "    open_pred = open_asr(audio)[\"text\"].lower()\n",
    "    # Append to output list\n",
    "    output.append({\"sentence\": sentence, \"metaPred\": meta_pred, \"openPred\": open_pred})\n",
    "\n",
    "output_df = pd.DataFrame(output)\n",
    "\n",
    "# Compute the WER for both models\n",
    "metaWER = wer.compute(predictions=output_df[\"metaPred\"], references=output_df[\"sentence\"])\n",
    "openWER = wer.compute(predictions=output_df[\"openPred\"], references=output_df[\"sentence\"])\n",
    "\n",
    "# Print the WER\n",
    "print(f\"The WER for the meta model is {metaWER} and for the open model is {openWER}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes on the Generator Function with `yield`:\n",
    "The yield keyword makes data a generator function. Unlike return, which exits the function and sends a value back to the caller, yield pauses the function's execution, saves its state, and allows it to resume from where it left off.\n",
    "\n",
    "When the generator is iterated (e.g., using for audio, sentence in data()), yield provides the next set of values (audio and sentence) without restarting the function. This makes it well-suited for scenarios where processing data in chunks or streams is required, such as handling large datasets or audio files.\n",
    "\n",
    "Can be interpreted as \"the generator function is triggered in the for loop. When the for loop loops to a new set of values, the generator function generates the audio and sentence output\"\n",
    "\n",
    "- When the for loop starts (e.g., for audio, sentence in data()), the generator function data is called for the first time.\n",
    "The generator starts executing, and when it encounters the first yield statement, it produces the first set of values (audio and sentence) and pauses.\n",
    "Resuming the Generator:\n",
    "\n",
    "- When the for loop moves to the next iteration, the generator resumes execution right after the last yield statement.\n",
    "It continues until it reaches the next yield, where it produces the next set of values, and pauses again."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
